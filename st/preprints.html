<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <title>Science and technology - Articles</title>
</head>
<body>
<!-----Begin----->

<p align="right">
<a href="http://paypal.me/loc789" target="_blank"><img src="https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif"/></a>
</p>

<ol>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2023, August 13). <a name="ST_Articles_Deconv" href="https://www.researchsquare.com/article/rs-3247106/v1" target="_blank" style="text-decoration: none"><b>Simple image deconvolution based on reverse image convolution and backpropagation algorithm</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Deconvolution task is not important in convolutional neural network (CNN) because it is not imperative to recover convoluted image when convolutional layer is important to extract features. However, the deconvolution task is useful in some cases of inspecting and reflecting a convolutional filter as well as trying to improve a generated image when information loss is not serious with regard to trade-off of information loss and specific features such as edge detection and sharpening. This research proposes a duplicated and reverse process of recovering a filtered image. Firstly, source layer and target layer are reversed in accordance with traditional image convolution so as to train the convolutional filter. Secondly, the trained filter is reversed again to derive a deconvolutional operator for recovering the filtered image. The reverse process is associated with backpropagation algorithm which is most popular in learning neural network. Experimental results show that the proposed technique in this research is better to learn the filters that focus on discovering pixel differences. Therefore, the main contribution of this research is to inspect convolutional filters from data.<br/>
            <i>Keywords</i>: convolutional neural network, convolutional filter, image deconvolution, backpropagation algorithm.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://www.researchsquare.com" target="_blank" style="text-decoration: none">Research Square</a>. Preprinted date is August 13, 2023.<br/>
            <i>Publisher</i>: American Journal Experts (<a href="https://www.aje.com" target="_blank" style="text-decoration: none">AJE</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            Online presenting the research &ldquo;Simple image deconvolution based on reverse image convolution and backpropagation algorithm&rdquo; (in 16th day) in the 3rd International Conference on Research Methodology for Qualitative and Quantitative Research 2023 (<a href="https://eudoxiaeducation.com/international-conference-eudoxia" target="_blank" style="text-decoration: none">COM-2023</a>), organized by Eudoxia Research University, New Castle, USA (<a href="https://eudoxiaresearchuniversity.us" target="_blank" style="text-decoration: none">ERU</a>) and Eudoxia Research Centre, Mumbai, Bangalore and Guwahati, India (<a href="http://eudoxiaeducation.com" target="_blank" style="text-decoration: none">ERC</a>), held on 16th - 17th November 2023.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="http://dx.doi.org/10.21203/rs.3.rs-3247106/v1" target="_blank" style="text-decoration: none">10.21203/rs.3.rs-3247106/v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://www.researchsquare.com/article/rs-3247106/v1" target="_blank" style="text-decoration: none">https://www.researchsquare.com/article/rs-3247106/v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2023, August 13). <a href="https://www.researchsquare.com/article/rs-3247106/v1" target="_blank" style="text-decoration: none"><i>Simple image deconvolution based on reverse image convolution and backpropagation algorithm</i></a>. <a href="https://www.researchsquare.com" target="_blank" style="text-decoration: none">Research Square</a> preprints 2023. doi: <a href="http://dx.doi.org/10.21203/rs.3.rs-3247106/v1" target="_blank" style="text-decoration: none">10.21203/rs.3.rs-3247106/v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Computer Science
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2022, June 28). <a name="ST_Articles_TLM" href="https://osf.io/42cbn" target="_blank" style="text-decoration: none"><b>Triangular Learner Model</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            User model is description of users’ information and characteristics in abstract level. User model is very important to adaptive software which aims to support user as much as possible. The process to construct user model is called user modeling. Within learning context where users are learners, the research proposes a so-called Triangular Learner Model (TLM) which is composed of three essential learners’ properties such as knowledge, learning style, and learning history. TLM is the user model that supports built-in inference mechanism. So the strong point of TLM is to reason out new information from users, based on mathematical tools. This paper focuses on fundamental algorithms and mathematical tools to construct three basic components of TLM such as knowledge sub-model, learning style sub-model, and learning history sub-model. In general, the paper is a summary of results from research on TLM. Algorithms and formulas are described by the succinct way.<br/>
            <i>Keywords</i>: user model, user modeling, adaptive learning, knowledge, learning style, learning history.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://osf.io/preprints" target="_blank" style="text-decoration: none">OSF Preprints</a>. Preprinted date is June 28, 2022.<br/>
            <i>Publisher</i>: Open Science Framework (<a href="https://osf.io" target="_blank" style="text-decoration: none">OSF</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            <a href="https://drive.google.com/file/d/1IXHpr3USCUHaWlU6vsTEbeSLhKIuj1ZT/view?usp=sharing" target="_blank" style="text-decoration: none">Online presented</a> in The 1st International Conference of TESOL &amp; Education (<a href="https://i-jte.org/icte" target="_blank" style="text-decoration: none">ICTE</a>) and VLTESOL2022, organized by Van Lang University (<a href="https://www.vanlanguni.edu.vn" target="_blank" style="text-decoration: none">VLU</a>), held on 22nd January 2022, Ho Chi Minh city, Vietnam.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="http://dx.doi.org/10.31219/osf.io/42cbn" target="_blank" style="text-decoration: none">10.31219/osf.io/42cbn</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://osf.io/42cbn" target="_blank" style="text-decoration: none">https://osf.io/42cbn</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2022, June 28). <a href="https://osf.io/42cbn" target="_blank" style="text-decoration: none"><i>Triangular Learner Model</i></a>. Open Science Framework (<a href="https://osf.io/preprints" target="_blank" style="text-decoration: none">OSF</a>) Preprints. doi:<a href="http://dx.doi.org/10.31219/osf.io/42cbn" target="_blank" style="text-decoration: none">10.31219/osf.io/42cbn</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Computer Science, Mathematics, Statistics, Education
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2022, June 27). <a name="ST_Articles_MinimaStudy" href="https://www.preprints.org/manuscript/202206.0361/v1" target="_blank" style="text-decoration: none"><b>A short study on minima distribution</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Global optimization is an imperative development of local optimization because there are many problems in artificial intelligence and machine learning requires highly acute solutions over entire domain. There are many methods to resolve the global optimization, which can be classified into three groups such as analytic methods (purely mathematical methods), probabilistic methods, and heuristic methods. Especially, heuristic methods like particle swarm optimization and ant bee colony attract researchers because their effective and practical techniques which are easy to be implemented by computer programming languages. However, these heuristic methods are lacking in theoretical mathematical fundamental. Fortunately, minima distribution establishes a strict mathematical relationship between optimized target function and its global minima. In this research, I try to study minima distribution and apply it into explaining convergence and convergence speed of optimization algorithms. Especially, weak conditions of convergence and monotonicity within minima distribution are drawn so as to be appropriate to practical optimization methods.<br/>
            <i>Keywords</i>: global optimization, minima distribution, particle swarm optimization, PSO.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://www.preprints.org" target="_blank" style="text-decoration: none">Preprints</a>. Preprinted date is June 27, 2022.<br/>
            <i>Publisher</i>: Multidisciplinary Digital Publishing Institute (<a href="https://www.mdpi.com" target="_blank" style="text-decoration: none">MDPI</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            Online presented in VANJ Conference 2022 (<a href="https://conf.vanj.jp/2022" target="_blank" style="text-decoration: none">VANJ2022</a>), organized by Vietnamese Academic Network in Japan (<a href="https://vanj.jp" target="_blank" style="text-decoration: none">VANJ</a>), held on 26th - 27th November 2022, University of Tokyo (Hongo Campus), Tokyo, Japan.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="http://dx.doi.org/10.20944/preprints202206.0361.v1" target="_blank" style="text-decoration: none">10.20944/preprints202206.0361.v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://www.preprints.org/manuscript/202206.0361/v1" target="_blank" style="text-decoration: none">https://www.preprints.org/manuscript/202206.0361/v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2022, June 27). <a href="https://www.preprints.org/manuscript/202206.0361/v1" target="_blank" style="text-decoration: none"><i>A short study on minima distribution</i></a>. <a href="https://www.preprints.org" target="_blank" style="text-decoration: none">Preprints</a> 2022, 2022060361. doi: <a href="http://dx.doi.org/10.20944/preprints202206.0361.v1" target="_blank" style="text-decoration: none">10.20944/preprints202206.0361.v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Mathematics, Statistics
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2022, February 3). <a name="ST_Articles_CARAR" href="https://www.researchsquare.com/article/rs-1322456/v2" target="_blank" style="text-decoration: none"><b>A Proposal of Two-step Autoregressive Model</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Autoregressive (AR) model and conditional autoregressive (CAR) model are specific regressive models in which independent variables and dependent variable imply the same object. They are powerful statistical tools to predict values based on correlation of time domain and space domain, which are useful in epidemiology analysis. In this research, I combine them by the simple way in which AR and CAR is estimated in two separate steps so as to cover time domain and space domain in spatial-temporal data analysis. Moreover, I integrate logistic model into CAR model, which aims to improve competence of autoregressive models.<br/>
            <i>Keywords</i>: autoregressive (AR) model, conditional autoregressive (CAR) model, logistic function, spatial-temporal data analysis.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://www.researchsquare.com" target="_blank" style="text-decoration: none">Research Square</a>. Preprinted date is February 3, 2022.<br/>
            <i>Publisher</i>: American Journal Experts (<a href="https://www.aje.com" target="_blank" style="text-decoration: none">AJE</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            <a href="https://www.maymeeting.org/conference/CSMA/1592s9171.html" target="_blank" style="text-decoration: none">Keynote Speaker</a> (online) with topic &ldquo;A Proposal of Two-step Autoregressive Model&rdquo; at The 4th International Conference on Computational Science and Numerical Algorithms (<a href="http://www.maymeeting.org/conference/CSMA2023" target="_blank" style="text-decoration: none">CSMA 2023</a>), organized by Engineering Information Institute (<a href="https://www.engii.org" target="_blank" style="text-decoration: none">Engii</a>), held on 30th May - 1st June 2023, Chengdu, China.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="http://dx.doi.org/10.21203/rs.3.rs-1322456/v2" target="_blank" style="text-decoration: none">10.21203/rs.3.rs-1322456/v2</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://www.researchsquare.com/article/rs-1322456/v2" target="_blank" style="text-decoration: none">https://www.researchsquare.com/article/rs-1322456/v2</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2022, February 3). <a href="https://www.researchsquare.com/article/rs-1322456/v2" target="_blank" style="text-decoration: none"><i>A Proposal of Two-step Autoregressive Model</i></a>. <a href="https://www.researchsquare.com" target="_blank" style="text-decoration: none">Research Square</a> preprints 2022. doi: <a href="http://dx.doi.org/10.21203/rs.3.rs-1322456/v2" target="_blank" style="text-decoration: none">10.21203/rs.3.rs-1322456/v2</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Statistics, Mathematics
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2022, February 2). <a name="ST_Articles_CA" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3976593" target="_blank" style="text-decoration: none"><b>Expectation Maximization Algorithm with Combinatorial Assumption</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Expectation maximization (EM) algorithm is a popular and powerful mathematical method for parameter estimation in case that there exist both observed data and hidden data. The EM process depends on an implicit relationship between observed data and hidden data which is specified by a mapping function in traditional EM and a joint probability density function (PDF) in practical EM. However, the mapping function is vague and impractical whereas the joint PDF is not easy to be defined because of heterogeneity between observed data and hidden data. The research aims to improve competency of EM by making it more feasible and easier to be specified, which removes the vagueness. Therefore, the research proposes an assumption that observed data is the combination of hidden data which is realized as an analytic function where data points are numerical. In other words, observed points are supposedly calculated from hidden points via regression model. Mathematical computations and proofs indicate feasibility and clearness of the proposed method which can be considered as an extension of EM.<br/>
            <i>Keywords</i>: expectation maximization (EM), observed data, hidden data, mapping function, joint probability density function, combinatorial assumption, regression model.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Posted</i>
        </td>
        <td valign="top">
            <a href="https://papers.ssrn.com/sol3/JELJOUR_Results.cfm?form_name=journalBrowse&journal_id=3191602" target="_blank" style="text-decoration: none">Computing Methodology eJournal</a>, Volume 5, Issue 4, February 7, 2022. Posted date is February 2, 2022.<br/>
            <i>Open Access</i>.<br/>
            <i>Publisher</i>: Social Science Research Network (<a href="https://www.ssrn.com" target="_blank" style="text-decoration: none">SSRN</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            <a href="http://cmstatistics.org/RegistrationsV2/EcoSta2022/viewSubmission.php?in=173&token=1o2nq6onn8p7q62s910s7o10nqp59770" target="_blank" style="text-decoration: none">Online presented</a> in The 5th International Conference on Econometrics and Statistics (<a href="http://www.cmstatistics.org/EcoSta2022" target="_blank" style="text-decoration: none">EcoSta 2022</a>), held on 4th - 6th June 2022, <a href="https://www.ryukoku.ac.jp" target="_blank" style="text-decoration: none">Ryukoku University</a>, Kyoto, Japan.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="https://dx.doi.org/10.2139/ssrn.3976593" target="_blank" style="text-decoration: none">10.2139/ssrn.3976593</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3976593" style="text-decoration: none">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3976593</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2022, February 2). <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3976593" target="_blank" style="text-decoration: none"><i>Expectation Maximization Algorithm with Combinatorial Assumption</i></a>. <a href="https://papers.ssrn.com/sol3/JELJOUR_Results.cfm?form_name=journalBrowse&journal_id=3191602" target="_blank" style="text-decoration: none">Computing Methodology eJournal</a>, 5(4). doi:<a href="https://dx.doi.org/10.2139/ssrn.3976593" target="_blank" style="text-decoration: none">10.2139/ssrn.3976593</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Statistics, Mathematics
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2020, November 9). <a name="ST_Articles_DyadicACMM" href="https://www.preprints.org/manuscript/202011.0266/v1" target="_blank" style="text-decoration: none"><b>Conditional Mixture Model for Modeling Attributed Dyadic Data</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Dyadic data contains co-occurrences of objects, which is often modeled by finite mixture model which in turn is learned by expectation maximization (EM) algorithm. Objects in traditional dyadic data are identified by names, causing the drawback which is that it is impossible to extract implicit valuable knowledge under objects. In this research, I propose the so-called attributed dyadic data (ADD) in which each object has an informative attribute and each co-occurrence of two objects is associated with a value. ADD is flexible and covers most of structures / forms of dyadic data. Conditional mixture model (CMM), which is a variant of finite mixture model, is applied into learning ADD. Moreover, a significant feature of CMM is that any co-occurrence of two objects is based on some conditional variable. As a result, CMM can predict or estimate co-occurrent values based on regression model, which extends applications of ADD and CMM.<br/>
            <i>Keywords</i>: dyadic data, co-occurrence data, attributed dyadic data (ADD), mixture model, conditional mixture model (CMM), regression model.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://www.preprints.org" target="_blank" style="text-decoration: none">Preprints</a>. Preprinted date is November 9, 2020.<br/>
            <i>Publisher</i>: Multidisciplinary Digital Publishing Institute (<a href="https://www.mdpi.com" target="_blank" style="text-decoration: none">MDPI</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            <a href="https://drive.google.com/file/d/1BiyatqhwVjO9C5bXYgBbQhG9gnb6uHOc/view?usp=sharing" target="_blank" style="text-decoration: none">Invited Speaker</a> (online) with topic &ldquo;Conditional mixture model for modeling attributed dyadic data&rdquo; at the 14th International Conference on Computer Science and Information Technology (<a href="http://www.iccsit.org" target="_blank" style="text-decoration: none">ICCSIT 2021</a>), October 15 - 17, 2021, Paris, France.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="http://dx.doi.org/10.20944/preprints202011.0266.v1" target="_blank" style="text-decoration: none">10.20944/preprints202011.0266.v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://www.preprints.org/manuscript/202011.0266/v1" target="_blank" style="text-decoration: none">https://www.preprints.org/manuscript/202011.0266/v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2020, November 1). <a href="https://www.preprints.org/manuscript/202011.0266/v1" target="_blank" style="text-decoration: none"><i>Conditional Mixture Model for Modeling Attributed Dyadic Data</i></a>. <a href="https://www.preprints.org" target="_blank" style="text-decoration: none">Preprints</a> 2020, 2020100550 (doi: <a href="http://dx.doi.org/10.20944/preprints202011.0266.v1" target="_blank" style="text-decoration: none">10.20944/preprints202011.0266.v1</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Statistics, Computer Science
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2020, October 28). <a name="ST_Articles_CMM_RM" href="https://www.preprints.org/manuscript/202010.0550/v2" target="_blank" style="text-decoration: none"><b>Conditional mixture model and its application for regression model</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Expectation maximization (EM) algorithm is a powerful mathematical tool for estimating statistical parameter when data sample contains hidden part and observed part. EM is applied to learn finite mixture model in which the whole distribution of observed variable is average sum of partial distributions. Coverage ratio of every partial distribution is specified by the probability of hidden variable. An application of mixture model is soft clustering in which cluster is modeled by hidden variable whereas each data point can be assigned to more than one cluster and degree of such assignment is represented by the probability of hidden variable. However, such probability in traditional mixture model is simplified as a parameter, which can cause loss of valuable information. Therefore, in this research I propose a so-called conditional mixture model (CMM) in which the probability of hidden variable is modeled as a full probabilistic density function (PDF) that owns individual parameter. CMM aims to extend mixture model. I also propose an application of CMM which is called adaptive regressive model (ARM). Traditional regression model is effective when data sample is scattered equally. If data points are grouped into clusters, regression model tries to learn a unified regression function which goes through all data points. Obviously, such unified function is not effective to evaluate response variable based on grouped data points. The concept “adaptive” of ARM means that ARM solves the ineffectiveness problem by selecting the best cluster of data points firstly and then evaluating response variable within such best cluster. In order words, ARM reduces estimation space of regression model so as to gain high accuracy in calculation.<br/>
            <i>Keywords</i>: expectation maximization (EM) algorithm, finite mixture model, conditional mixture model, regression model, adaptive regressive model (ARM).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://www.preprints.org" target="_blank" style="text-decoration: none">Preprints</a>. Preprinted date is October 28, 2020.<br/>
            <i>Publisher</i>: Multidisciplinary Digital Publishing Institute (<a href="https://www.mdpi.com" target="_blank" style="text-decoration: none">MDPI</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            Online presenting the research &ldquo;Conditional mixture model and its application for regression model&rdquo; (in 19th day) in the 2nd International Conference on Multidisciplinary Research Trends in European, Asian, and African Countries 2024 (<a href="https://eudoxiaresearchuniversity.us/international-conference-2" target="_blank" style="text-decoration: none">IRTEC 2.0-2024</a>), organized by Eudoxia Research University, New Castle, USA (<a href="https://eudoxiaresearchuniversity.us" target="_blank" style="text-decoration: none">ERU</a>) and Eudoxia Research Centre, Mumbai, Bangalore and Guwahati, India (<a href="http://eudoxiaeducation.com" target="_blank" style="text-decoration: none">ERC</a>), in collaboration with Samarpan Group, India, held on 18th - 19th January 2024.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="http://dx.doi.org/10.20944/preprints202010.0550.v2" target="_blank" style="text-decoration: none">10.20944/preprints202010.0550.v2</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://www.preprints.org/manuscript/202010.0550/v2" target="_blank" style="text-decoration: none">https://www.preprints.org/manuscript/202010.0550/v2</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2020, October 28). <a href="https://www.preprints.org/manuscript/202010.0550/v2" target="_blank" style="text-decoration: none"><i>Conditional Mixture Model and Its Application for Regression Model</i></a>. <a href="https://www.preprints.org" target="_blank" style="text-decoration: none">Preprints</a> 2020, 2020100550 (doi: <a href="http://dx.doi.org/10.20944/preprints202010.0550.v2" target="_blank" style="text-decoration: none">10.20944/preprints202010.0550.v2</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Statistics, Computer Science
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a>, <a href="http://httt.uit.edu.vn/web/student/intro/chitietgv/GV11" target="_blank" style="text-decoration: none">Minh-Phung T. Do</a> (2018, January 18). <a name="ST_Articles_GreenFallFull" href="https://peerj.com/preprints/26444" target="_blank" style="text-decoration: none"><b>A Novel Collaborative Filtering Algorithm by Bit Mining Frequent Itemsets</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Journal Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Collaborative filtering (CF) is a popular technique in recommendation study. Concretely, items which are recommended to user are determined by surveying her/his communities. There are two main CF approaches, which are memory-based and model-based. I propose a new CF model-based algorithm by mining frequent itemsets from rating database. Hence items which belong to frequent itemsets are recommended to user. My CF algorithm gives immediate response because the mining task is performed at offline process-mode. I also propose another so-called Roller algorithm for improving the process of mining frequent itemsets. Roller algorithm is implemented by heuristic assumption <i>“The larger the support of an item is, the higher it’s likely that this item will occur in some frequent itemset”</i>. It models upon doing white-wash task, which rolls a roller on a wall in such a way that is capable of picking frequent itemsets. Moreover I provide enhanced techniques such as bit representation, bit matching and bit mining in order to speed up recommendation process. These techniques take advantages of bitwise operations (<i>AND</i>, <i>NOT</i>) so as to reduce storage space and make algorithms run faster.<br/>
            <i>Keywords</i>: collaborative filtering, mining frequent itemsets, bit matching, bit mining.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Accepted</i>
        </td>
        <td valign="top">
            <a href="http://www.scientificadvances.co.in/about-this-journal/17" target="_blank" style="text-decoration: none">International Journal of Applied Mathematics and Machine Learning</a>, Scientific Advances Publishers. Acceptance date is July 15, 2016.<br/>
            <i>ISSN</i>: 2394-2258.<br/>
            <i>Editors</i>: Li Li, Shuaiqi Liu, Mehmet Koc, José Luis López-Bonilla, Balan Sethuramalingam, Bin Guo, Loc Nguyen, Hind Rustum Mohammed Shaaban, Srinivas Nowduri.<br/>
            <i>Publisher</i>: <a href="http://www.scientificadvances.co.in" target="_blank" style="text-decoration: none">Scientific Advances Publishers</a>, India.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://peerj.com/preprints" target="_blank" style="text-decoration: none">PeerJ Preprints</a>, volume 6, issue e26444v1. Preprinted date is January 18, 2018.<br/>
            <i>ISSN</i>: 2167-9843.<br/>
            <i>Publisher</i>: <a href="https://peerj.com" target="_blank" style="text-decoration: none">PeerJ</a>.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            Presenting the research &ldquo;A Novel Collaborative Filtering Algorithm by Bit Mining Frequent Itemsets&rdquo; in the 6th International Research Conference on Multidisciplinary Learning: Exploring Languages, Authorship and Publishing, Business, Technology, Culture, and Society (<a href="https://www.facebook.com/photo/?fbid=728848565925155" target="_blank" style="text-decoration: none">ICEPD2023</a>) with the theme &ldquo;Future Thinkers at the Frontline of Today&apos;s Global Challenges&rdquo;, organized by International Cross-cultural Exchange and Professional Development-Thailand (<a href="https://icepdthailand.org" target="_blank" style="text-decoration: none">ICEPD-Thailand</a>), held on 8th - 11th December 2023, Ho Chi Minh city, Vietnam.<br/>
            <br/>
            Online presenting the research &ldquo;A Novel Collaborative Filtering Algorithm by Bit Mining Frequent Itemsets&rdquo; (in 11st day) in the 2nd International Conference on Recent Trends in Multidisciplinary Research 2023 (<a href="https://eudoxiaresearchuniversity.us/international-conference-live" target="_blank" style="text-decoration: none">ICROM 2.0</a>), organized by Eudoxia Research University, New Castle, USA (<a href="https://eudoxiaresearchuniversity.us" target="_blank" style="text-decoration: none">ERU</a>) and Eudoxia Research Centre, Mumbai, Bangalore and Guwahati, India (<a href="http://eudoxiaeducation.com" target="_blank" style="text-decoration: none">ERC</a>), in association with Bharati Vidyapeeth Deemed University, held on 11st - 12nd November 2023.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="https://doi.org/10.7287/peerj.preprints.26444v1" target="_blank" style="text-decoration: none">10.7287/peerj.preprints.26444v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://peerj.com/preprints/26444" target="_blank" style="text-decoration: none">https://peerj.com/preprints/26444</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a>, <a href="http://httt.uit.edu.vn/web/student/intro/chitietgv/GV11" target="_blank" style="text-decoration: none">Do, M.-P. T.</a> (2018, January 18). <a href="https://peerj.com/preprints/26444" target="_blank" style="text-decoration: none"><i>A Novel Collaborative Filtering Algorithm by Bit Mining Frequent Itemsets</i></a>. <a href="https://peerj.com/preprints" target="_blank" style="text-decoration: none">PeerJ Preprints</a>, 6(e26444v1). doi:<a href="https://doi.org/10.7287/peerj.preprints.26444v1" target="_blank" style="text-decoration: none">10.7287/peerj.preprints.26444v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            <i>PeerJ Preprints</i>: Crossref, Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Computer Science
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


</ol>

<p>
    Last updated June 2024
</p>
<p>
    <a href="http://www.locnguyen.net/misc/indexing" target="_blank">Abstracting and indexing</a>
</p>

<!-----End----->
</body>
</html>
