<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html>
<head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <title>Science and technology - Articles</title>
</head>
<body>
<!-----Begin----->

<p align="right">
<a href="http://paypal.me/loc789" target="_blank"><img src="https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif"/></a>
</p>

<ol>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2023, August 13). <a name="ST_Articles_Deconv" href="https://www.researchsquare.com/article/rs-3247106/v1" target="_blank" style="text-decoration: none"><b>Simple image deconvolution based on reverse image convolution and backpropagation algorithm</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Deconvolution task is not important in convolutional neural network (CNN) because it is not imperative to recover convoluted image when convolutional layer is important to extract features. However, the deconvolution task is useful in some cases of inspecting and reflecting a convolutional filter as well as trying to improve a generated image when information loss is not serious with regard to trade-off of information loss and specific features such as edge detection and sharpening. This research proposes a duplicated and reverse process of recovering a filtered image. Firstly, source layer and target layer are reversed in accordance with traditional image convolution so as to train the convolutional filter. Secondly, the trained filter is reversed again to derive a deconvolutional operator for recovering the filtered image. The reverse process is associated with backpropagation algorithm which is most popular in learning neural network. Experimental results show that the proposed technique in this research is better to learn the filters that focus on discovering pixel differences. Therefore, the main contribution of this research is to inspect convolutional filters from data.<br/>
            <i>Keywords</i>: convolutional neural network, convolutional filter, image deconvolution, backpropagation algorithm.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://www.researchsquare.com" target="_blank" style="text-decoration: none">Research Square</a>. Preprinted date is August 13, 2023.<br/>
            <i>Publisher</i>: American Journal Experts (<a href="https://www.aje.com" target="_blank" style="text-decoration: none">AJE</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            Online presenting the research &ldquo;Simple image deconvolution based on reverse image convolution and backpropagation algorithm&rdquo; (in 16th day) in the 3rd International Conference on Research Methodology for Qualitative and Quantitative Research 2023 (<a href="https://eudoxiaeducation.com/international-conference-eudoxia" target="_blank" style="text-decoration: none">COM-2023</a>), organized by Eudoxia Research University, New Castle, USA (<a href="https://eudoxiaresearchuniversity.us" target="_blank" style="text-decoration: none">ERU</a>) and Eudoxia Research Centre, Mumbai, Bangalore and Guwahati, India (<a href="http://eudoxiaeducation.com" target="_blank" style="text-decoration: none">ERC</a>), held on 16th - 17th November 2023.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="http://dx.doi.org/10.21203/rs.3.rs-3247106/v1" target="_blank" style="text-decoration: none">10.21203/rs.3.rs-3247106/v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://www.researchsquare.com/article/rs-3247106/v1" target="_blank" style="text-decoration: none">https://www.researchsquare.com/article/rs-3247106/v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2023, August 13). <a href="https://www.researchsquare.com/article/rs-3247106/v1" target="_blank" style="text-decoration: none"><i>Simple image deconvolution based on reverse image convolution and backpropagation algorithm</i></a>. <a href="https://www.researchsquare.com" target="_blank" style="text-decoration: none">Research Square</a> preprints 2023. doi: <a href="http://dx.doi.org/10.21203/rs.3.rs-3247106/v1" target="_blank" style="text-decoration: none">10.21203/rs.3.rs-3247106/v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Computer Science
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a>, Hassan I. Abdalla, <a href="https://www.researchgate.net/profile/Ali_Amer3" target="_blank" style="text-decoration: none">Ali Abdullah Amer</a> (2022, November 1). <a name="ST_Articles_TutorialPSO" href="https://osf.io/hs5bj" target="_blank" style="text-decoration: none"><b>Tutorial on particle swarm optimization and its combinations to other evolutionary algorithms</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Local optimization with convex function is solved perfectly by traditional mathematical methods such as Newton-Raphson and gradient descent but it is not easy to solve the global optimization with arbitrary function although there are some purely mathematical approaches such as approximation, cutting plane, branch and bound, and interval method which can be impractical because of their complexity and high computation cost. Recently, some evolutional algorithms which are inspired from biological activities are proposed to solve the global optimization by acceptable heuristic level. Among them is particle swarm optimization (PSO) algorithm which is proved as an effective and feasible solution for global optimization in real applications. Although the ideology of PSO is not complicated, it derives many variants, which can make new researchers confused. Therefore, this tutorial focuses on describing, systemizing, and classifying PSO by succinct and straightforward way. Moreover, combinations of PSO and other evolutional algorithms for improving PSO itself or solving other advanced problems are mentioned too.<br/>
            <i>Keywords</i>: particle swarm optimization (PSO), evolutional algorithms, global optimization.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://osf.io/preprints" target="_blank" style="text-decoration: none">OSF Preprints</a>. Preprinted date is November 1, 2022.<br/>
            <i>Publisher</i>: Open Science Framework (<a href="https://osf.io" target="_blank" style="text-decoration: none">OSF</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            <a href="http://www.iccsit.org/invited.html" target="_blank" style="text-decoration: none">Keynote Speaker</a> (online) with the speech &ldquo;Tutorial on Particle Swarm Optimization&rdquo; at the 15th International Conference on Computer Science and Information Technology (<a href="http://www.iccsit.org" target="_blank" style="text-decoration: none">ICCSIT2022</a>), held on 14th - 16th October 2022, virtual conference.<br/>
            <br/>
            <a href="https://www.seminarjan.org/conference/CISE/1542s9023.html" target="_blank" style="text-decoration: none">Keynote Speaker</a> (online via video) with topic &ldquo;Tutorial on particle swarm optimization and its combinations to other evolutionary algorithms&rdquo; at The 14th International Conference on Computational Intelligence and Software Engineering (<a href="https://www.seminarjan.org/conference/CISE2022" target="_blank" style="text-decoration: none">CISE2022</a>), 16th - 18th December 2022, Guilin, China.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="http://dx.doi.org/10.31219/osf.io/hs5bj" target="_blank" style="text-decoration: none">10.31219/osf.io/hs5bj</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://osf.io/hs5bj" target="_blank" style="text-decoration: none">https://osf.io/hs5bj</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a>, Abdalla, H. I., &amp; <a href="http://orcid.org/0000-0001-7186-7216" target="_blank" style="text-decoration: none">Amer, A. A.</a> (2022, November 1). <a href="https://osf.io/hs5bj" target="_blank" style="text-decoration: none"><i>Tutorial on particle swarm optimization and its combinations to other evolutionary algorithms</i></a>. Open Science Framework (<a href="https://osf.io/preprints" target="_blank" style="text-decoration: none">OSF</a>) Preprints. doi:<a href="http://dx.doi.org/10.31219/osf.io/hs5bj" target="_blank" style="text-decoration: none">10.31219/osf.io/hs5bj</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Computer Science, Mathematics
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2022, June 28). <a name="ST_Articles_TLM" href="https://osf.io/42cbn" target="_blank" style="text-decoration: none"><b>Triangular Learner Model</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            User model is description of users’ information and characteristics in abstract level. User model is very important to adaptive software which aims to support user as much as possible. The process to construct user model is called user modeling. Within learning context where users are learners, the research proposes a so-called Triangular Learner Model (TLM) which is composed of three essential learners’ properties such as knowledge, learning style, and learning history. TLM is the user model that supports built-in inference mechanism. So the strong point of TLM is to reason out new information from users, based on mathematical tools. This paper focuses on fundamental algorithms and mathematical tools to construct three basic components of TLM such as knowledge sub-model, learning style sub-model, and learning history sub-model. In general, the paper is a summary of results from research on TLM. Algorithms and formulas are described by the succinct way.<br/>
            <i>Keywords</i>: user model, user modeling, adaptive learning, knowledge, learning style, learning history.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://osf.io/preprints" target="_blank" style="text-decoration: none">OSF Preprints</a>. Preprinted date is June 28, 2022.<br/>
            <i>Publisher</i>: Open Science Framework (<a href="https://osf.io" target="_blank" style="text-decoration: none">OSF</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            <a href="https://drive.google.com/file/d/1IXHpr3USCUHaWlU6vsTEbeSLhKIuj1ZT/view?usp=sharing" target="_blank" style="text-decoration: none">Online presented</a> in The 1st International Conference of TESOL &amp; Education (<a href="https://i-jte.org/icte" target="_blank" style="text-decoration: none">ICTE</a>) and VLTESOL2022, organized by Van Lang University (<a href="https://www.vanlanguni.edu.vn" target="_blank" style="text-decoration: none">VLU</a>), held on 22nd January 2022, Ho Chi Minh city, Vietnam.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="http://dx.doi.org/10.31219/osf.io/42cbn" target="_blank" style="text-decoration: none">10.31219/osf.io/42cbn</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://osf.io/42cbn" target="_blank" style="text-decoration: none">https://osf.io/42cbn</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2022, June 28). <a href="https://osf.io/42cbn" target="_blank" style="text-decoration: none"><i>Triangular Learner Model</i></a>. Open Science Framework (<a href="https://osf.io/preprints" target="_blank" style="text-decoration: none">OSF</a>) Preprints. doi:<a href="http://dx.doi.org/10.31219/osf.io/42cbn" target="_blank" style="text-decoration: none">10.31219/osf.io/42cbn</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Computer Science, Mathematics, Statistics, Education
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2022, June 27). <a name="ST_Articles_MinimaStudy" href="https://www.preprints.org/manuscript/202206.0361/v1" target="_blank" style="text-decoration: none"><b>A short study on minima distribution</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Global optimization is an imperative development of local optimization because there are many problems in artificial intelligence and machine learning requires highly acute solutions over entire domain. There are many methods to resolve the global optimization, which can be classified into three groups such as analytic methods (purely mathematical methods), probabilistic methods, and heuristic methods. Especially, heuristic methods like particle swarm optimization and ant bee colony attract researchers because their effective and practical techniques which are easy to be implemented by computer programming languages. However, these heuristic methods are lacking in theoretical mathematical fundamental. Fortunately, minima distribution establishes a strict mathematical relationship between optimized target function and its global minima. In this research, I try to study minima distribution and apply it into explaining convergence and convergence speed of optimization algorithms. Especially, weak conditions of convergence and monotonicity within minima distribution are drawn so as to be appropriate to practical optimization methods.<br/>
            <i>Keywords</i>: global optimization, minima distribution, particle swarm optimization, PSO.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://www.preprints.org" target="_blank" style="text-decoration: none">Preprints</a>. Preprinted date is June 27, 2022.<br/>
            <i>Publisher</i>: Multidisciplinary Digital Publishing Institute (<a href="https://www.mdpi.com" target="_blank" style="text-decoration: none">MDPI</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            Online presented in VANJ Conference 2022 (<a href="https://conf.vanj.jp/2022" target="_blank" style="text-decoration: none">VANJ2022</a>), organized by Vietnamese Academic Network in Japan (<a href="https://vanj.jp" target="_blank" style="text-decoration: none">VANJ</a>), held on 26th - 27th November 2022, University of Tokyo (Hongo Campus), Tokyo, Japan.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="http://dx.doi.org/10.20944/preprints202206.0361.v1" target="_blank" style="text-decoration: none">10.20944/preprints202206.0361.v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://www.preprints.org/manuscript/202206.0361/v1" target="_blank" style="text-decoration: none">https://www.preprints.org/manuscript/202206.0361/v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2022, June 27). <a href="https://www.preprints.org/manuscript/202206.0361/v1" target="_blank" style="text-decoration: none"><i>A short study on minima distribution</i></a>. <a href="https://www.preprints.org" target="_blank" style="text-decoration: none">Preprints</a> 2022, 2022060361. doi: <a href="http://dx.doi.org/10.20944/preprints202206.0361.v1" target="_blank" style="text-decoration: none">10.20944/preprints202206.0361.v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Mathematics, Statistics
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2022, February 3). <a name="ST_Articles_CARAR" href="https://www.researchsquare.com/article/rs-1322456/v2" target="_blank" style="text-decoration: none"><b>A Proposal of Two-step Autoregressive Model</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Autoregressive (AR) model and conditional autoregressive (CAR) model are specific regressive models in which independent variables and dependent variable imply the same object. They are powerful statistical tools to predict values based on correlation of time domain and space domain, which are useful in epidemiology analysis. In this research, I combine them by the simple way in which AR and CAR is estimated in two separate steps so as to cover time domain and space domain in spatial-temporal data analysis. Moreover, I integrate logistic model into CAR model, which aims to improve competence of autoregressive models.<br/>
            <i>Keywords</i>: autoregressive (AR) model, conditional autoregressive (CAR) model, logistic function, spatial-temporal data analysis.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://www.researchsquare.com" target="_blank" style="text-decoration: none">Research Square</a>. Preprinted date is February 3, 2022.<br/>
            <i>Publisher</i>: American Journal Experts (<a href="https://www.aje.com" target="_blank" style="text-decoration: none">AJE</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            <a href="https://www.maymeeting.org/conference/CSMA/1592s9171.html" target="_blank" style="text-decoration: none">Keynote Speaker</a> (online) with topic &ldquo;A Proposal of Two-step Autoregressive Model&rdquo; at The 4th International Conference on Computational Science and Numerical Algorithms (<a href="http://www.maymeeting.org/conference/CSMA2023" target="_blank" style="text-decoration: none">CSMA 2023</a>), organized by Engineering Information Institute (<a href="https://www.engii.org" target="_blank" style="text-decoration: none">Engii</a>), held on 30th May - 1st June 2023, Chengdu, China.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="http://dx.doi.org/10.21203/rs.3.rs-1322456/v2" target="_blank" style="text-decoration: none">10.21203/rs.3.rs-1322456/v2</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://www.researchsquare.com/article/rs-1322456/v2" target="_blank" style="text-decoration: none">https://www.researchsquare.com/article/rs-1322456/v2</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2022, February 3). <a href="https://www.researchsquare.com/article/rs-1322456/v2" target="_blank" style="text-decoration: none"><i>A Proposal of Two-step Autoregressive Model</i></a>. <a href="https://www.researchsquare.com" target="_blank" style="text-decoration: none">Research Square</a> preprints 2022. doi: <a href="http://dx.doi.org/10.21203/rs.3.rs-1322456/v2" target="_blank" style="text-decoration: none">10.21203/rs.3.rs-1322456/v2</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Statistics, Mathematics
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2022, February 2). <a name="ST_Articles_CA" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3976593" target="_blank" style="text-decoration: none"><b>Expectation Maximization Algorithm with Combinatorial Assumption</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Expectation maximization (EM) algorithm is a popular and powerful mathematical method for parameter estimation in case that there exist both observed data and hidden data. The EM process depends on an implicit relationship between observed data and hidden data which is specified by a mapping function in traditional EM and a joint probability density function (PDF) in practical EM. However, the mapping function is vague and impractical whereas the joint PDF is not easy to be defined because of heterogeneity between observed data and hidden data. The research aims to improve competency of EM by making it more feasible and easier to be specified, which removes the vagueness. Therefore, the research proposes an assumption that observed data is the combination of hidden data which is realized as an analytic function where data points are numerical. In other words, observed points are supposedly calculated from hidden points via regression model. Mathematical computations and proofs indicate feasibility and clearness of the proposed method which can be considered as an extension of EM.<br/>
            <i>Keywords</i>: expectation maximization (EM), observed data, hidden data, mapping function, joint probability density function, combinatorial assumption, regression model.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Posted</i>
        </td>
        <td valign="top">
            <a href="https://papers.ssrn.com/sol3/JELJOUR_Results.cfm?form_name=journalBrowse&journal_id=3191602" target="_blank" style="text-decoration: none">Computing Methodology eJournal</a>, Volume 5, Issue 4, February 7, 2022. Posted date is February 2, 2022.<br/>
            <i>Open Access</i>.<br/>
            <i>Publisher</i>: Social Science Research Network (<a href="https://www.ssrn.com" target="_blank" style="text-decoration: none">SSRN</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            <a href="http://cmstatistics.org/RegistrationsV2/EcoSta2022/viewSubmission.php?in=173&token=1o2nq6onn8p7q62s910s7o10nqp59770" target="_blank" style="text-decoration: none">Online presented</a> in The 5th International Conference on Econometrics and Statistics (<a href="http://www.cmstatistics.org/EcoSta2022" target="_blank" style="text-decoration: none">EcoSta 2022</a>), held on 4th - 6th June 2022, <a href="https://www.ryukoku.ac.jp" target="_blank" style="text-decoration: none">Ryukoku University</a>, Kyoto, Japan.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="https://dx.doi.org/10.2139/ssrn.3976593" target="_blank" style="text-decoration: none">10.2139/ssrn.3976593</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3976593" style="text-decoration: none">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3976593</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2022, February 2). <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3976593" target="_blank" style="text-decoration: none"><i>Expectation Maximization Algorithm with Combinatorial Assumption</i></a>. <a href="https://papers.ssrn.com/sol3/JELJOUR_Results.cfm?form_name=journalBrowse&journal_id=3191602" target="_blank" style="text-decoration: none">Computing Methodology eJournal</a>, 5(4). doi:<a href="https://dx.doi.org/10.2139/ssrn.3976593" target="_blank" style="text-decoration: none">10.2139/ssrn.3976593</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Statistics, Mathematics
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2021, December 12). <a name="ST_Articles_Interpolation" href="https://osf.io/tn67p" target="_blank" style="text-decoration: none"><b>An extension of Lagrange interpolation to approximate derivative, integral and bivariate function</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Lagrange interpolation is the effective method to approximate an arbitrary function by a polynomial. But there is a need to estimate derivative and integral given a set of points. Although it is possible to make Lagrange interpolation first, which produces Lagrange polynomial; after that we take derivative or integral on such polynomial. However this approach does not result out the best estimation of derivative and integral. This research proposes a different approach that makes approximation of derivative and integral based on point data first, which in turn applies Lagrange interpolation into the approximation. Moreover, the research also proposes an extension of Lagrange interpolation to bivariate function, in which interpolation polynomial is converted as two-variable polynomial.<br/>
            <i>Keywords</i>: Lagrange interpolation, polynomial, approximation.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://osf.io/preprints" target="_blank" style="text-decoration: none">OSF Preprints</a>. Preprinted date is December 12, 2021.<br/>
            <i>Publisher</i>: Open Science Framework (<a href="https://osf.io" target="_blank" style="text-decoration: none">OSF</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="http://dx.doi.org/10.31219/osf.io/tn67p" target="_blank" style="text-decoration: none">10.31219/osf.io/tn67p</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://osf.io/tn67p" target="_blank" style="text-decoration: none">https://osf.io/tn67p</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2021, December 12). <a href="https://osf.io/tn67p" target="_blank" style="text-decoration: none"><i>An extension of Lagrange interpolation to approximate derivative, integral and bivariate function</i></a>. Open Science Framework (<a href="https://osf.io/preprints" target="_blank" style="text-decoration: none">OSF</a>) Preprints. doi:<a href="http://dx.doi.org/10.31219/osf.io/tn67p" target="_blank" style="text-decoration: none">10.31219/osf.io/tn67p</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Mathematics
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2020, November 9). <a name="ST_Articles_DyadicACMM" href="https://www.preprints.org/manuscript/202011.0266/v1" target="_blank" style="text-decoration: none"><b>Conditional Mixture Model for Modeling Attributed Dyadic Data</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Dyadic data contains co-occurrences of objects, which is often modeled by finite mixture model which in turn is learned by expectation maximization (EM) algorithm. Objects in traditional dyadic data are identified by names, causing the drawback which is that it is impossible to extract implicit valuable knowledge under objects. In this research, I propose the so-called attributed dyadic data (ADD) in which each object has an informative attribute and each co-occurrence of two objects is associated with a value. ADD is flexible and covers most of structures / forms of dyadic data. Conditional mixture model (CMM), which is a variant of finite mixture model, is applied into learning ADD. Moreover, a significant feature of CMM is that any co-occurrence of two objects is based on some conditional variable. As a result, CMM can predict or estimate co-occurrent values based on regression model, which extends applications of ADD and CMM.<br/>
            <i>Keywords</i>: dyadic data, co-occurrence data, attributed dyadic data (ADD), mixture model, conditional mixture model (CMM), regression model.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://www.preprints.org" target="_blank" style="text-decoration: none">Preprints</a>. Preprinted date is November 9, 2020.<br/>
            <i>Publisher</i>: Multidisciplinary Digital Publishing Institute (<a href="https://www.mdpi.com" target="_blank" style="text-decoration: none">MDPI</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            <a href="https://drive.google.com/file/d/1BiyatqhwVjO9C5bXYgBbQhG9gnb6uHOc/view?usp=sharing" target="_blank" style="text-decoration: none">Invited Speaker</a> (online) with topic &ldquo;Conditional mixture model for modeling attributed dyadic data&rdquo; at the 14th International Conference on Computer Science and Information Technology (<a href="http://www.iccsit.org" target="_blank" style="text-decoration: none">ICCSIT 2021</a>), October 15 - 17, 2021, Paris, France.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="http://dx.doi.org/10.20944/preprints202011.0266.v1" target="_blank" style="text-decoration: none">10.20944/preprints202011.0266.v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://www.preprints.org/manuscript/202011.0266/v1" target="_blank" style="text-decoration: none">https://www.preprints.org/manuscript/202011.0266/v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2020, November 1). <a href="https://www.preprints.org/manuscript/202011.0266/v1" target="_blank" style="text-decoration: none"><i>Conditional Mixture Model for Modeling Attributed Dyadic Data</i></a>. <a href="https://www.preprints.org" target="_blank" style="text-decoration: none">Preprints</a> 2020, 2020100550 (doi: <a href="http://dx.doi.org/10.20944/preprints202011.0266.v1" target="_blank" style="text-decoration: none">10.20944/preprints202011.0266.v1</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Statistics, Computer Science
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2020, October 28). <a name="ST_Articles_CMM_RM" href="https://www.preprints.org/manuscript/202010.0550/v2" target="_blank" style="text-decoration: none"><b>Conditional mixture model and its application for regression model</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Expectation maximization (EM) algorithm is a powerful mathematical tool for estimating statistical parameter when data sample contains hidden part and observed part. EM is applied to learn finite mixture model in which the whole distribution of observed variable is average sum of partial distributions. Coverage ratio of every partial distribution is specified by the probability of hidden variable. An application of mixture model is soft clustering in which cluster is modeled by hidden variable whereas each data point can be assigned to more than one cluster and degree of such assignment is represented by the probability of hidden variable. However, such probability in traditional mixture model is simplified as a parameter, which can cause loss of valuable information. Therefore, in this research I propose a so-called conditional mixture model (CMM) in which the probability of hidden variable is modeled as a full probabilistic density function (PDF) that owns individual parameter. CMM aims to extend mixture model. I also propose an application of CMM which is called adaptive regressive model (ARM). Traditional regression model is effective when data sample is scattered equally. If data points are grouped into clusters, regression model tries to learn a unified regression function which goes through all data points. Obviously, such unified function is not effective to evaluate response variable based on grouped data points. The concept “adaptive” of ARM means that ARM solves the ineffectiveness problem by selecting the best cluster of data points firstly and then evaluating response variable within such best cluster. In order words, ARM reduces estimation space of regression model so as to gain high accuracy in calculation.<br/>
            <i>Keywords</i>: expectation maximization (EM) algorithm, finite mixture model, conditional mixture model, regression model, adaptive regressive model (ARM).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://www.preprints.org" target="_blank" style="text-decoration: none">Preprints</a>. Preprinted date is October 28, 2020.<br/>
            <i>Publisher</i>: Multidisciplinary Digital Publishing Institute (<a href="https://www.mdpi.com" target="_blank" style="text-decoration: none">MDPI</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            Online presenting the research &ldquo;Conditional mixture model and its application for regression model&rdquo; (in 19th day) in the 2nd International Conference on Multidisciplinary Research Trends in European, Asian, and African Countries 2024 (<a href="https://eudoxiaresearchuniversity.us/international-conference-2" target="_blank" style="text-decoration: none">IRTEC 2.0-2024</a>), organized by Eudoxia Research University, New Castle, USA (<a href="https://eudoxiaresearchuniversity.us" target="_blank" style="text-decoration: none">ERU</a>) and Eudoxia Research Centre, Mumbai, Bangalore and Guwahati, India (<a href="http://eudoxiaeducation.com" target="_blank" style="text-decoration: none">ERC</a>), in collaboration with Samarpan Group, India, held on 18th - 19th January 2024.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="http://dx.doi.org/10.20944/preprints202010.0550.v2" target="_blank" style="text-decoration: none">10.20944/preprints202010.0550.v2</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://www.preprints.org/manuscript/202010.0550/v2" target="_blank" style="text-decoration: none">https://www.preprints.org/manuscript/202010.0550/v2</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2020, October 28). <a href="https://www.preprints.org/manuscript/202010.0550/v2" target="_blank" style="text-decoration: none"><i>Conditional Mixture Model and Its Application for Regression Model</i></a>. <a href="https://www.preprints.org" target="_blank" style="text-decoration: none">Preprints</a> 2020, 2020100550 (doi: <a href="http://dx.doi.org/10.20944/preprints202010.0550.v2" target="_blank" style="text-decoration: none">10.20944/preprints202010.0550.v2</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Statistics, Computer Science
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2018, July 10). <a name="ST_Articles_NQC" href="https://osf.io/vumhn" target="_blank" style="text-decoration: none"><b>Proposal of Evaluating Patients&apos; Satisfaction about Quality of Healthcare System by Non-parametric Quality Control</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Preprinted Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Hospital quality assessment is key subject in hospital management. Patient satisfaction called criterion <i>F</i> is an important quality measure. It is necessary to use <i>F</i> as control factor to improve gradually the hospital management process. Because <i>F</i> is fuzzy, I propose a so-called non-parametric quality control (NQC) method that is combination of non-parametric test and quality control chart in order to estimate <i>F</i>. If <i>F</i> becomes a vector composed of many sub-criteria then, NQC method is extended as multivariate NQC (MNQC) method used for evaluating many concerned opinions of patients. MNQC replaces the distance between observation and null hypothesis by their Pearson coefficient. This research is a proposal because I do not make experiments on NQC and MNQC yet.<br/>
            <i>Keywords</i>: patient satisfaction, hospital management, non-parametric test, quality control chart, non-parametric quality control, multivariate non-parametric quality control.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://osf.io/preprints" target="_blank" style="text-decoration: none">OSF Preprints</a>. Preprinted date is July 10, 2018.<br/>
            <i>Publisher</i>: Open Science Framework (<a href="https://osf.io" target="_blank" style="text-decoration: none">OSF</a>).
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="http://dx.doi.org/10.17605/OSF.IO/VUMHN" target="_blank" style="text-decoration: none">10.17605/OSF.IO/VUMHN</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://osf.io/vumhn" target="_blank" style="text-decoration: none">https://osf.io/vumhn</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2018, July 10). <a href="https://osf.io/vumhn" target="_blank" style="text-decoration: none"><i>Proposal of Evaluating Patients&apos; Satisfaction about Quality of Healthcare System by Non-parametric Quality Control</i></a>. Open Science Framework (<a href="https://osf.io/preprints" target="_blank" style="text-decoration: none">OSF</a>) Preprints. doi:<a href="http://dx.doi.org/10.17605/OSF.IO/VUMHN" target="_blank" style="text-decoration: none">10.17605/OSF.IO/VUMHN</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Statistics
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a>, <a href="http://httt.uit.edu.vn/web/student/intro/chitietgv/GV11" target="_blank" style="text-decoration: none">Minh-Phung T. Do</a> (2018, January 18). <a name="ST_Articles_GreenFallFull" href="https://peerj.com/preprints/26444" target="_blank" style="text-decoration: none"><b>A Novel Collaborative Filtering Algorithm by Bit Mining Frequent Itemsets</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Journal Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Collaborative filtering (CF) is a popular technique in recommendation study. Concretely, items which are recommended to user are determined by surveying her/his communities. There are two main CF approaches, which are memory-based and model-based. I propose a new CF model-based algorithm by mining frequent itemsets from rating database. Hence items which belong to frequent itemsets are recommended to user. My CF algorithm gives immediate response because the mining task is performed at offline process-mode. I also propose another so-called Roller algorithm for improving the process of mining frequent itemsets. Roller algorithm is implemented by heuristic assumption <i>“The larger the support of an item is, the higher it’s likely that this item will occur in some frequent itemset”</i>. It models upon doing white-wash task, which rolls a roller on a wall in such a way that is capable of picking frequent itemsets. Moreover I provide enhanced techniques such as bit representation, bit matching and bit mining in order to speed up recommendation process. These techniques take advantages of bitwise operations (<i>AND</i>, <i>NOT</i>) so as to reduce storage space and make algorithms run faster.<br/>
            <i>Keywords</i>: collaborative filtering, mining frequent itemsets, bit matching, bit mining.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Accepted</i>
        </td>
        <td valign="top">
            <a href="http://www.scientificadvances.co.in/about-this-journal/17" target="_blank" style="text-decoration: none">International Journal of Applied Mathematics and Machine Learning</a>, Scientific Advances Publishers. Acceptance date is July 15, 2016.<br/>
            <i>ISSN</i>: 2394-2258.<br/>
            <i>Editors</i>: Li Li, Shuaiqi Liu, Mehmet Koc, José Luis López-Bonilla, Balan Sethuramalingam, Bin Guo, Loc Nguyen, Hind Rustum Mohammed Shaaban, Srinivas Nowduri.<br/>
            <i>Publisher</i>: <a href="http://www.scientificadvances.co.in" target="_blank" style="text-decoration: none">Scientific Advances Publishers</a>, India.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://peerj.com/preprints" target="_blank" style="text-decoration: none">PeerJ Preprints</a>, volume 6, issue e26444v1. Preprinted date is January 18, 2018.<br/>
            <i>ISSN</i>: 2167-9843.<br/>
            <i>Publisher</i>: <a href="https://peerj.com" target="_blank" style="text-decoration: none">PeerJ</a>.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            Presenting the research &ldquo;A Novel Collaborative Filtering Algorithm by Bit Mining Frequent Itemsets&rdquo; in the 6th International Research Conference on Multidisciplinary Learning: Exploring Languages, Authorship and Publishing, Business, Technology, Culture, and Society (<a href="https://www.facebook.com/photo/?fbid=728848565925155" target="_blank" style="text-decoration: none">ICEPD2023</a>) with the theme &ldquo;Future Thinkers at the Frontline of Today&apos;s Global Challenges&rdquo;, organized by International Cross-cultural Exchange and Professional Development-Thailand (<a href="https://icepdthailand.org" target="_blank" style="text-decoration: none">ICEPD-Thailand</a>), held on 8th - 11th December 2023, Ho Chi Minh city, Vietnam.<br/>
            <br/>
            Online presenting the research &ldquo;A Novel Collaborative Filtering Algorithm by Bit Mining Frequent Itemsets&rdquo; (in 11st day) in the 2nd International Conference on Recent Trends in Multidisciplinary Research 2023 (<a href="https://eudoxiaresearchuniversity.us/international-conference-live" target="_blank" style="text-decoration: none">ICROM 2.0</a>), organized by Eudoxia Research University, New Castle, USA (<a href="https://eudoxiaresearchuniversity.us" target="_blank" style="text-decoration: none">ERU</a>) and Eudoxia Research Centre, Mumbai, Bangalore and Guwahati, India (<a href="http://eudoxiaeducation.com" target="_blank" style="text-decoration: none">ERC</a>), in association with Bharati Vidyapeeth Deemed University, held on 11st - 12nd November 2023.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="https://doi.org/10.7287/peerj.preprints.26444v1" target="_blank" style="text-decoration: none">10.7287/peerj.preprints.26444v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://peerj.com/preprints/26444" target="_blank" style="text-decoration: none">https://peerj.com/preprints/26444</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a>, <a href="http://httt.uit.edu.vn/web/student/intro/chitietgv/GV11" target="_blank" style="text-decoration: none">Do, M.-P. T.</a> (2018, January 18). <a href="https://peerj.com/preprints/26444" target="_blank" style="text-decoration: none"><i>A Novel Collaborative Filtering Algorithm by Bit Mining Frequent Itemsets</i></a>. <a href="https://peerj.com/preprints" target="_blank" style="text-decoration: none">PeerJ Preprints</a>, 6(e26444v1). doi:<a href="https://doi.org/10.7287/peerj.preprints.26444v1" target="_blank" style="text-decoration: none">10.7287/peerj.preprints.26444v1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            <i>PeerJ Preprints</i>: Crossref, Google Scholar.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Computer Science
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2018, January 17). <a name="ST_Articles_MixtureTestingIncomplete" href="http://osf.io/whvq8" target="_blank" style="text-decoration: none"><b>A Maximum Likelihood Mixture Approach for Multivariate Hypothesis Testing in case of Incomplete Data</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Journal Article
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Multivariate hypothesis testing becomes more and more necessary when data is in the process of changing from scalar and univariate format to multivariate format, especially financial and biological data is often constituted of n-dimension vectors. Likelihood ratio test is the best method that applies the test on mean of multivariate sample with known or unknown covariance matrix but it is impossible to use likelihood ratio test in case of incomplete data when the data incompletion gets popular because of many reasons in reality. Therefore, this research proposes a new approach that gives an ability to apply likelihood ratio test into incomplete data. Instead of replacing missing values in incomplete sample by estimated values, this approach classifies incomplete sample into groups and each group is represented by a potential or partial distribution. All partial distributions are unified into a mixture model which is optimized via expectation maximization (EM) algorithm. Finally, likelihood ratio test is performed on mixture model instead of incomplete sample. This research provides a thorough description of proposed approach and mathematical proof that is necessary to such approach. The comparison of mixture model approach and filling missing values approach is also discussed in this research.<br/>
            <i>Keywords</i>: maximum likelihood, mixture model, multivariate hypothesis testing, incomplete data.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Accepted</i>
        </td>
        <td valign="top">
            Journal of Mathematics and System Science (<a href="http://www.davidpublisher.org/Home/Journal/JMSS" target="_blank" style="text-decoration: none">JMSS</a>). Acceptance date is July 22, 2013.<br/>
            <i>ISSN online</i>: 2159-5305, <i>ISSN print</i>: 2159-5291, <i>Open Access</i>.<br/>
            <i>Editors</i>: Assia Guezane-Lakoud, William P. Fox, Elisa Francomano, Sergo A. Episkoposian, Elizbar Nadaraya, Alexander Nikolaevich Raikov, Baha ŞEN, Claudio Cuevas, Wattanavadee Sriwattanapongse, Mohammad Mehdi Rashidi.<br/>
            <i>Publisher</i>: <a href="http://www.davidpublisher.org" target="_blank" style="text-decoration: none">David Publishing Company</a>, USA.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://osf.io/preprints" target="_blank" style="text-decoration: none">OSF Preprints</a>. Preprinted date is January 17, 2018.<br/>
            <i>Publisher</i>: <a href="https://osf.io" target="_blank" style="text-decoration: none">Open Science Framework</a>.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="http://osf.io/whvq8" target="_blank" style="text-decoration: none">http://osf.io/whvq8</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2018, January 17). <a href="http://osf.io/whvq8" target="_blank" style="text-decoration: none"><i>A Maximum Likelihood Mixture Approach for Multivariate Hypothesis Testing in case of Incomplete Data</i></a>. Open Science Framework (<a href="https://osf.io/preprints" target="_blank" style="text-decoration: none">OSF</a>) Preprints. Retrieved from <a href="http://osf.io/whvq8" target="_blank" style="text-decoration: none">http://osf.io/whvq8</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            <i>JMSS</i>: Academic Keys, BASE, CEPS, CQVIP, CSTJ, CiteFactor, CSA, DBH, EBSCO, EZB, getCITED, Google Scholar, Index Copernicus, InfoBase Index, InnoSpace, NSD, OCLC, Open J-Gate, PAIS, PBN, ProQuest, Scholar Steer, SHERPA, SIS, SJournal Index, Summon Serials Solutions, Turkish Education Index, UCSD, UDL, UlrichsWeb, WZB
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Statistics
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2018, January 17). <a name="ST_Articles_NonparametricTesting" href="http://osf.io/tj9cf" target="_blank" style="text-decoration: none"><b>Nonparametric Hypothesis Testing Report</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Study Report
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            This report is the brief survey of nonparametric hypothesis testing. It includes four main sections about hypothesis testing, one additional section discussing goodness-of-fit and conclusion section. <i>Sign test section</i> gives an overview of nonparametric testing, which begins with the test on sample median without assumption of normal distribution. <i>Signed-rank test section</i> and <i>rank-sum test section</i> concern improvements of sign test. The prominence of signed-rank test is to be able to test sample mean based on the assumption about symmetric distribution. Rank-sum test discards the task of assigning and counting plus signs and so it is the most effective method among ranking test methods. <i>Nonparametric ANOVA section</i> discusses application of analysis of variance (ANOVA) in nonparametric model. ANOVA is useful to compare and evaluate various data samples at the same time. <i>Nonparametric goodness-fit-test section</i>, an additional section, focuses on different hypothesis, which measure the distribution similarity between two samples. It determines whether two samples have the same distribution without concerning how the form of distribution is. <i>The last section</i> is the conclusion. Note that in this report terms <i>sample</i> and <i>data sample</i> have the same meaning. A sample contains many data points. Each <i>data point</i> is also called an observation.<br/>
            <i>Keywords</i>: nonparametric testing, nonparametric ANOVA.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Accepted</i>
        </td>
        <td valign="top">
            Science Journal Of Mathematics and Statistics (<a href="http://www.sjpub.org/sjms.html" target="_blank" style="text-decoration: none">SJMS</a>). Acceptance date is July 17, 2013.<br/>
            <i>ISSN</i>: 2276-6324, <i>Open Access</i>.<br/>
            <i>Publisher</i>: <a href="http://www.sjpub.org" target="_blank" style="text-decoration: none">Science Journal Publication</a>.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Preprinted</i>
        </td>
        <td valign="top">
            <a href="https://osf.io/preprints" target="_blank" style="text-decoration: none">OSF Preprints</a>. Preprinted date is January 17, 2018.<br/>
            <i>Publisher</i>: <a href="https://osf.io" target="_blank" style="text-decoration: none">Open Science Framework</a>.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Awarded</i>
        </td>
        <td valign="top">
            <a href="https://drive.google.com/file/d/0ByHQY9CungG-MmJXVmZtOWVtUE0/view?usp=sharing" target="_blank" style="text-decoration: none">Certified</a> by Science Journal Publication
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="http://osf.io/tj9cf" target="_blank" style="text-decoration: none">http://osf.io/tj9cf</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2018, January 17). <a href="http://osf.io/tj9cf" target="_blank" style="text-decoration: none"><i>Nonparametric Hypothesis Testing Report</i></a>. Open Science Framework (<a href="https://osf.io/preprints" target="_blank" style="text-decoration: none">OSF</a>) Preprints. Retrieved from <a href="http://osf.io/tj9cf" target="_blank" style="text-decoration: none">http://osf.io/tj9cf</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
            <i>SJMS</i>: CrossRef, Gale, Google Scholar, Summon Serials Solutions, UlrichsWeb
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Statistics
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


<li>
<a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Loc Nguyen</a> (2013, June 5). <a name="ST_Articles_SeparatedHyperplaneSignTest" href="http://dx.doi.org/10.13140/RG.2.2.20886.86080/1" target="_blank" style="text-decoration: none"><b>A new method to determine separated hyper-plane for non-parametric sign test in multivariate data</b></a><br/>
<table border="0" cellpadding="4" cellspacing="4">
    <tr>
        <td valign="top">
            <i>Type</i>
        </td>
        <td valign="top">
            Conference Presentation
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Abstract</i>
        </td>
        <td valign="top">
            Non-parametric testing is very necessary in case that the statistical sample does not conform normal distribution or we have no knowledge about sample distribution. Sign test is a popular and effective test for non-parametric model but it cannot be applied into multivariate data in which observations are vectors because the ordering and comparative operators are not defined in n-dimension vector space. So, this research proposes a new approach to perform sign test on multivariate sample by using a hyper-plane to separate multi-dimensional observations into two sides. Therefore, it is possible for the sign test to assign plus signs and minus signs to observations in each side. Moreover, this research introduces a new method to determine the separated hyper-plane. This method is a variant of support vector machine (SVM), thus, the optimized hyper-plane is the one that contains null hypothesis and splits observations as discriminatively as possible.<br/>
            <i>Keywords</i>: separated hyper-plane, non-parametric sign test.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Presented</i>
        </td>
        <td valign="top">
            STATISTICS and its INTERACTIONS with OTHER DISCIPLINES (<a href="http://siod.tdtu.edu.vn/index.php/siod/2013" target="_blank" style="text-decoration: none">SIOD 2013</a>).<br/>
            <i>Editors</i>: Vinh-Danh Le, Audri Mukhopadhyay, Gia-Thu Pham.<br/>
            <i>Publisher</i>: <a href="http://www.tdt.edu.vn" target="_blank" style="text-decoration: none">Ton Duc Thang University</a>.<br/>
            <i>Place</i> and <i>date</i>: Ton Duc Thang University, Ho Chi Minh, Vietnam, June 4 - 7, 2013.
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Identifiers</i>
        </td>
        <td valign="top">
            DOI: <a href="http://dx.doi.org/10.13140/RG.2.2.20886.86080/1" target="_blank" style="text-decoration: none">10.13140/RG.2.2.20886.86080/1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Links</i>
        </td>
        <td valign="top">
            <a href="https://goo.gl/NGQ8jq" target="_blank" style="text-decoration: none">https://goo.gl/NGQ8jq</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Citations</i>
        </td>
        <td valign="top">
            <a href="http://www.locnguyen.net" target="_blank" style="text-decoration: none">Nguyen, L.</a> (2013, June 5). <a href="http://dx.doi.org/10.13140/RG.2.2.20886.86080" target="_blank" style="text-decoration: none"><i>A new method to determine separated hyper-plane for non-parametric sign test in multivariate data</i></a>. In V.-D. Le, A. Mukhopadhyay, &amp; G.-T. Pham (Ed.), STATISTICS and its INTERACTIONS with OTHER DISCIPLINES (<a href="http://siod.tdtu.edu.vn/index.php/siod/2013" target="_blank" style="text-decoration: none">SIOD 2013</a>). Ho Chi Minh: <a href="http://www.tdt.edu.vn" target="_blank" style="text-decoration: none">Ton Duc Thang University</a>. doi:<a href="http://dx.doi.org/10.13140/RG.2.2.20886.86080/1" target="_blank" style="text-decoration: none">10.13140/RG.2.2.20886.86080/1</a>
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Cited</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Indexed</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Metrics</i>
        </td>
        <td valign="top">
        </td>
    </tr>
    <tr>
        <td valign="top">
            <i>Categories</i>
        </td>
        <td valign="top">
            Statistics, Mathematics
        </td>
    </tr>
</table>
<p>
    &nbsp;
</p>
</li>


</ol>

<p>
    Last updated June 2024
</p>
<p>
    <a href="http://www.locnguyen.net/misc/indexing" target="_blank">Abstracting and indexing</a>
</p>

<!-----End----->
</body>
</html>
